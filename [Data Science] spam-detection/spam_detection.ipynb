{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add1b372",
   "metadata": {},
   "source": [
    "# Email Analysis and Classification for SPAM Detection\n",
    "\n",
    "**Project Description**\n",
    "\n",
    "A company specialized in Artificial Intelligenceâ€“based automation, aims to develop a software library for analyzing and classifying incoming emails.  \n",
    "The main objective is to identify **SPAM emails** in order to perform in-depth content analysis and improve the security of corporate communications.\n",
    "\n",
    "The project originates from the CEOâ€™s need to better understand **trends, content, and behaviors** associated with SPAM emails. These insights will be used to:\n",
    "- enhance anti-spam filters;\n",
    "- strengthen communication security;\n",
    "- support strategic decisions in the cybersecurity domain.\n",
    "\n",
    "---\n",
    "\n",
    "**Project Objectives**\n",
    "\n",
    "Based on an email dataset provided by the CTO, the project aims to:\n",
    "\n",
    "- Train a **classifier** to identify SPAM emails.\n",
    "- Identify the **main topics** among emails classified as SPAM.\n",
    "- Compute the **semantic distance between topics** to evaluate the heterogeneity of SPAM content.\n",
    "- Extract information about **organizations mentioned** in **NON-SPAM** emails.\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "ðŸ‘‰ https://github.com/ProfAI/natural-language-processing/tree/main/datasets/Verifica%20Finale%20-%20Spam%20Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e4fb3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3265d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tqdm import tqdm\\nimport time\\nimport joblib\\nimport random\\n\\n# nlp import\\nimport gensim\\nfrom gensim.utils import simple_preprocess\\nfrom gensim import corpora, models\\nfrom bertopic import BERTopic\\n\\nimport nltk\\nfrom nltk.stem import WordNetLemmatizer\\nfrom nltk.corpus import stopwords\\n\\nimport spacy\\nimport spacy.displacy as displacy\\nimport re\\n\\nfrom pprint import pprint\\n\\n# models \\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.linear_model import LogisticRegression \\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.ensemble import RandomForestClassifier\\nimport xgboost as xgb\\nfrom lightgbm import LGBMClassifier\\n\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.preprocessing import MaxAbsScaler\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, cross_validate\\n\\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, classification_report, make_scorer\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# nlp import\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "from bertopic import BERTopic\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import spacy.displacy as displacy\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# models \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, cross_validate\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, classification_report, make_scorer\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2ee7c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea73b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09f7020",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7fbe0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dataset = \"https://raw.githubusercontent.com/ProfAI/natural-language-processing/refs/heads/main/datasets/Verifica%20Finale%20-%20Spam%20Detection/spam_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed149bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\nthe transport v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\nhpl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n&gt;\\n&gt;\\nj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\ndear ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
       "2           3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\nthe transport v...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\nhpl ...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\n>\\n>\\nj...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\ndear ...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(link_dataset)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea69ff1",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035770f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antispam_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
